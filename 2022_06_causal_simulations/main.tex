\documentclass{beamer}

\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{2212}{-}
\usecolortheme{beaver}
\usepackage{caption}
\usepackage{tabularx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage[style=verbose, backend=biber]{biblatex}

\DeclarePairedDelimiter\norm{\lVert}{\rVert}%

\addbibresource{references.bib}

\setbeamertemplate{navigation symbols}{}

\begin{document}

\title{Simulation methods in Causal Inference}
\date{}
\maketitle

\begin{frame}
	\frametitle{Index}
	\begin{itemize}
		\item Potential Outcome Framework
		\item Problem Statement
		\item Monte Carlo based
			\begin{itemize}
				\item Placebo Design
				\item Structured Design
				\item Bootstrapping
			\end{itemize}
		\item Generative Deep Learning based
			\begin{itemize}
				\item Wasserstein Generative Adversarial Networks
				\item Variational Autoencoders
			\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Potential Outcomes Framework}
	\begin{columns}
		\begin{column}{0.5 \textwidth}
		\begin{table}
			\centering
			\begin{tabularx}{\textwidth}{| c | c | c | c |} 
			\hline 
			\textbf{subject} & $ Y_{t}(u) $  & $ Y_{c}(u) $ & $ Y_{t}(u) - Y_{c}(u) $ \\
			\hline
				Joe    & 130     & 135    & −5 \\
				Mary   & 140     & 150    & −10 \\
				Sally  & 135     & 125    & 10 \\
				Bob    & 135     & 150    & −15 \\
			\hline
			\hline
			\end{tabularx}
		\end{table}
		\end{column}
		\begin{column}{0.5 \textwidth}
		\begin{table}
			\centering
			\begin{tabularx}{\textwidth}{| c | c | c | c |} 
			\hline 
			\textbf{subject} & $ Y_{t}(u) $  & $ Y_{c}(u) $ & $ Y_{t}(u) - Y_{c}(u) $ \\
			\hline
				Joe    & 130     & ? & ? \\
				Mary   & ? & 150    &  ? \\
				Sally  & ? & 125    &  ? \\
				Bob    & 135     & ? & ? \\
			\hline
			\hline
			\end{tabularx}
		\end{table}
		\end{column}
	\end{columns}	
	\footnotetext[1]{https://www.wikiwand.com/en/Rubin\_causal\_model}
\end{frame}

\begin{frame}
	\frametitle{Treatment Effect Measures}
	Average Treatment Effect (ATE):
	$ \mathbb{E}[Y_i(1) - Y_i(0)] $
	Conditional Average Treatment Effect (CATE):
	$ \mathbb{E}[Y_i(1) - Y_i(0) | W_i = 1] $
\end{frame}

\begin{frame}
	\frametitle{Problem Statement}
	\begin{itemize}
		\item A lot of different estimators for treatment effect eg. Propensity score matching, Double ML.
		\item Estimators have similar asymptotic properties but difference finite-sample properties.
		\item In correlational models, performance of an estimator can be measured by
			splitting data into training and test sets.
		\item True causal effect is unknown for most datasets, so estimator performances
			can't be compared for a given dataset.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Problem Statement: Example}
	\begin{table}[h!]
		\centering
		\begin{tabularx}{\textwidth}{||c c c||} 
		 \hline
		 \textbf{Estimators}  & \textbf{ATE Estimate} & \textbf{Std. Dev.} \\
		 \hline\hline
		 Difference of Means & 886.30 & 277.37 \\ 
		 Double Machine Learning & 370.94 & 394.68 \\
		 Causal Bart & 818.79 & 184.46 \\
		 Propensity Score Matching & 1079.13 & 158.59 \\
		 \hline
		\end{tabularx}
		\caption*{ATE estimates on the National Support Work Demonstration temporary employment program and income dataset \footcite{parikh2022evaluating}}
		\label{table:estimates}
	\end{table}
\end{frame}

\begin{frame}
	\frametitle{Finite sample performance on data from RCTs}
	\begin{itemize}
		\item Problem Statement: Lack of observational datasets for which the interventional effect is known.
		\item For associational models, it is easy to split data and evaluate the performance.
		\item For evaluating causal estimates, we need an observational dataset and the true causal effects
		\item This approach uses RCT datasets to generate an observational dataset. The RCT can give the true causal effect values and that can then be verified by estimation on the observational dataset.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{How and when to use experimental data to evaluate}
	\begin{itemize}
		\item Use some of the covariates (which affect the outcome) to bias the random
			selection.
		\item Using the baised treatment selection, sample from the RCT dataset.
		\item Gives a biased observational dataset, where the bias covariates are the 
			confounders.
		\item Use estimators on these observational datasets to estimate the true 
			causal effect.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Placebo Design}
	Use the placebo arm with treatment effect 0, and try to estimate it using the methods.
\end{frame}

\begin{frame}
	\frametitle{Structured Design}
	Assume a data generating structure, and try to estimate the treatment effect from the structure.
\end{frame}

\begin{frame}
	\frametitle{Mostly Harmless Simulations}
	\begin{itemize}
		\item Both the methods don't really work and just bootstrapping is a better method.
		\item Unrealistic assumptions on the data generating process lead to unreliable results.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Using Wasserstein Generative Adversarial Networks (GANs)}
	\begin{itemize}
		\item Not a single estimator which works well for all.
		\item Systematic simulation studies can be helpful for selecting methods.
		\item Generated data closely resembles the actual data.
		\item DGP like kernel desnity doesn't work because of oversmooth in case of finite samples. Bootstrp doesn't replace the original samples and there is overlap.
	\end{itemize}
	\footnotetext{Athey, Susan, et al. "Using wasserstein generative adversarial networks for the design of monte carlo simulations." Journal of Econometrics (2021)}
\end{frame}

\begin{frame}
	\frametitle{Using Variational Auto Encoders}
	\begin{itemize}
		\item Relaxes conditional ignorability. Allows users to specify treatment effects and confounding bias.
		\item Paper only considers the problem of estimating ATE i.e $ \tau = \mathbb{E}[Y(1) - Y(0)] $.
		\item Method to generate synthetic data with two features: 1) User-specified causal treatment effect, heterogeneity, and endogeneity. 2) simulated samples that are stochastically indistinguishable from the observed data sample of interest.
	\end{itemize}
	\footnotetext{Parikh, Harsh, et al. "Evaluating Causal Inference Methods." arXiv preprint arXiv:2202.04208 (2022)}
\end{frame}

\begin{frame}
	Assumed data generating process:
	\begin{equation}
		\begin{split}
			\{ \epsilon_{X, i}, \epsilon_{Z, i}, \epsilon_{Y, i} \}_{i=1}^N & \sim \mathcal{N}(\mathbb{0}, \mathbb{1}) \\
			\{ U_i \} & \sim \mathcal{N}(0, 1) \\
			X_i & \sim \phi_X(\epsilon_(X, i) \\
			Z_i & \sim \phi_Z(X_i, U_i, \epsilon_{Z, i}) \\
			Y_i(1) & \sim \phi_{Y_i(1)} (X_i, U_i, \epsilon_{Y, i}) \\
			Y_i(0) & \sim \phi_{Y_i(0)} (X_i, U_i, \epsilon_{Y, i})
		\end{split}
	\end{equation}
	User defined inputs/assumptions:
	\begin{equation}
		\begin{split}
			f(x) &= \mathbb{E}[Y(1) - Y(0) | X=x] \\
			g(x, z) &= \mathbb{E}[Y(z) | X=x, Z=z] - \mathbb{E}[Y(z) | X=x, Z=1-z] \\
		\end{split}
	\end{equation}
\end{frame}
\begin{frame}
	\begin{equation}
		\begin{split}
			\mathbf{\min}_{\theta} & \mathbb{E}[d((X, Y, Z), (X', Y', Z'))] + \alpha \norm{\mathbb{E}[Y'(1) - Y'(0) | X' = x'] -f(x') } \\
						& + \beta \norm{\mathbb{E}[Y'(z') | X'=x', Z'=z] - \mathbb{E}[Y'(z') | X'=x', Z'=1-z'] -g(x', z')}
		\end{split}
	\end{equation}

	\begin{itemize}
		\item First term: Some distance measure on the distributions.
		\item Second term: Difference between the user-specified causal effect and expected from the generated data.
		\item Third term: Difference between estimated confounding and user-specified.
	\end{itemize}
	Two VAEs, first one to learn $ P(X | Z) $ and second one to learn $ P((Y(1), Y(0)) | X, Z) $.
\end{frame}
\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{fig_3.jpg}
	\end{figure}
\end{frame}
\begin{frame}
	\begin{figure}
		\includegraphics[width=\textwidth]{fig_4.jpg}
	\end{figure}
\end{frame}

\end{document}
