\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usecolortheme{beaver}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{titlecaps}
\usepackage{fancyvrb}

\def\ci{\perp\!\!\!\!\!\perp}

\newtheorem{proposition}{Proposition}
\Addlcwords{for a is but and with of in as the etc on to if}

\setbeamertemplate{section in toc}{\inserttocsectionnumber.~\inserttocsection}
\usetheme{Boadilla}
\makeatletter
\setbeamertemplate{footline}{%
    \leavevmode%
    \hbox{%
        \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
            \usebeamerfont{author in head/foot}\insertshortauthor\expandafter\beamer@ifempty\expandafter{\beamer@shortinstitute}{}{~~(\insertshortinstitute)}
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
            \usebeamerfont{title in head/foot}\insertshorttitle
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=.15\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
            \usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}
            \insertframenumber{} / \inserttotalframenumber\hspace*{2ex} 
        \end{beamercolorbox}}%
        \vskip0pt%
    }
\makeatother

\begin{document}

\title[]{Parameterizing Mixed Data Linear Structural Equation Models}
\author{Ankur Ankan}
\date{}

\maketitle

\begin{frame}{Structural Equation Models}
	\begin{figure}
		\centering
		\begin{subfigure}{0.6 \textwidth}
			\centering
			\includegraphics[page=1]{figures.pdf}
		\end{subfigure}%
		\begin{subfigure}{0.4 \textwidth}
			\centering
			\begin{equation*}
				\begin{split}
					\l_2 &= \beta_{11} \l_1 + \zeta_1 \\
					y_6 &= \lambda_{26} \l_2 + \epsilon_6 \\
				\end{split}
			\end{equation*}
		\end{subfigure}	
		\caption{Example of a linear SEM }
	\end{figure}

	\begin{itemize}
		\item A Structural Equation Model (SEM) represents causal relationships between variables.
		\item The parameters on the edge (called the \emph{path
			coefficients}) represent the strength of the
			relationship.
		\item If the model is standardized (i.e. error variances are $ 1 $, the parameters ar
	\end{itemize}
\end{frame}

\begin{frame}{Parameterization of a Linear SEM}
	<TODO: Add figure>
	\begin{itemize}
		\item In Linear SEM with continuous variables, each edge is parameterized
			using a \emph{path coefficient}.
		\item It represents the strenght of relationship between the variables
			due to that edge.
		\item Allows for application of \emph{path analysis}, and can easily
			compute things like indirect effect, total effects etc.
			<TODO: Add example>
	\end{itemize}
\end{frame}

\begin{frame}{Estimating these parameters}
	\begin{itemize}
		\item In Linear SEM, these path coefficients can be estimated by regressing
			variables on their parents. <TODO: Example>
		\item But for categorical the coefficients are more difficult.
	\end{itemize}
\end{frame}

\begin{frame}{Estimating these through residuals}
	The estimation problem can also be reformulated in terms of residuals using FWL.
	% Introduce the FWL theorem.
	% What applying this to estimation of looks like.
\end{frame}

\begin{frame}{What happens in the case of mixed data}
	What we require to extend this estimation to mixed data.
	1. Some way to have residuals for mixed data.
	2. Some kind of effect size measure for this mixed residuals.
\end{frame}

\begin{frame}{Residuals: Continuous Variablese}
	Simple difference between true and predicted values.
\end{frame}

\begin{frame}{Residuals: Ordinal Variables}
	Given an ordinal variable $ Y $ and an estimate $ \hat{p}(y) $ of $
	p(y) $, LS-Residual for sample $ y_i $ is defined as:
	$$ R_{y_i} = \hat{p}(Y < y_i) - \hat{p}(Y > y_i) $$
	\vspace{1em}

	For the binary case with $ Y \in \{0, 1\} $:
	$$ R_{y_i} = y_i - \hat{p}(Y = 1) $$
	\vspace{1em}

	For the conditional case for sample $ (y|z)_i $,
	$$ R_{y_i | z_i} = \hat{p}(Y < y_i | Z=z_i) - \hat{p}(Y>y_i|Z=z_i) $$

	$ \hat{p}(y) = \begin{array}{llll} Y_0 & Y_1 & Y_2 & Y_3 \\ 0.1 & 0.3 & 0.5 & 0.1 \end{array} $
	\begin{itemize}
		\item If $ y = Y_2 $, $ R_{y} = \hat{p}(Y < Y_2) - \hat{p}(Y > Y_2) = 0.3 $
		\item If $ y = Y_3 $, $ R_{y} = \hat{p}(Y < Y_3) - \hat{p}(Y > Y_3) = 0.9 $
	\end{itemize}
\end{frame}

\begin{frame}{Residuals: Categorical variables}
	$\hat{p}(Y) = \begin{array}{ll} Y_0 & Y_1 \\ 0.3 & 0.7 \end{array} $
	\begin{itemize}	
		\item If $ y = Y_0 $, $ R_{y} = Y_0 - \hat{p}(Y=1) = -0.7 $
		\item If $ y = Y_1 $, $ R_{y} = Y_1 - \hat{p}(Y=1) = 0.3 $
	\end{itemize}
\end{frame}

\begin{frame}{Residuals Summary}
	We get a matrix of continuous valued residuals for each case.
\end{frame}

\begin{frame}{Effect Size: Canonical Correlation}
	Can't directly use correlation coefficient as we have matrix of
	residuals but canonical correlation based things can be used.

	What is canonical correlation?
\end{frame}

\begin{frame}
	How does these parameters look like. Show on the adult income dataset
	or something.

	This also has the multiplicative property of path analysis. Show an
	example.
\end{frame}

\begin{frame}{CI Testing based on canonical correlation}
	Can use something like Pillai's trace.
\end{frame}

\begin{frame}{Results of CI testing}
	Canonical correlation results in better calibration and power in high
	dimensional settings.
\end{frame}

\begin{frame}{Conclusion/Remaining problems}
	Not sure how addition rule of path coefficients would work.
	For CI tests, asymptotic theory isn't clear.
\end{frame}

\end{document}
