\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usecolortheme{beaver}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{titlecaps}
\usepackage{fancyvrb}

\def\ci{\perp\!\!\!\!\!\perp}

\newtheorem{proposition}{Proposition}
\Addlcwords{for a is but and with of in as the etc on to if}

\setbeamertemplate{section in toc}{\inserttocsectionnumber.~\inserttocsection}
\usetheme{Boadilla}
\makeatletter
\setbeamertemplate{footline}{%
    \leavevmode%
    \hbox{%
        \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
            \usebeamerfont{author in head/foot}\insertshortauthor\expandafter\beamer@ifempty\expandafter{\beamer@shortinstitute}{}{~~(\insertshortinstitute)}
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
            \usebeamerfont{title in head/foot}\insertshorttitle
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=.15\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
            \usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}
            \insertframenumber{} / \inserttotalframenumber\hspace*{2ex} 
        \end{beamercolorbox}}%
        \vskip0pt%
    }
\makeatother

\begin{document}

\title[]{Statistical and Causal Robustness for Causal Null Hypothesis Tests}
\date{}

\maketitle

\begin{frame}{Background}
	Observational Data -> DAG -> Identification -> Estimation

	% TODO: Insert a figure here showing the steps.

	Workflow for estimating causal effect in observational data.

	\begin{itemize}
		\item Constructing DAG is difficult form data.
		\item Typically rely on either structure learning, or just domain knowledge to construct the model.
		\item No clear way to verify if the constructed model is correct.
	\end{itemize}	
\end{frame}

\begin{frame}{Background}
	Observational Data -> DAG -> Identification -> Estimation
	
	% TODO: An example of an identified and non-identified model.
	\begin{itemize}
		\item Given the model, need to check whether the parameter is estimable.
		\item Pearl's do-calculus gives a complete solution.
		\item But has limited practical applicability.
		\item Lots of special case solutions: Backdoor, Front-door, Instrumental Variables (IV).
		\item Iterate through these and see if can be estimated.
		\item Each of them make different assumptions about the model.
		\item These observations are hard to test in observational data.
		\item Given a correctly specified model, statistically robust estimators are available, i.e. unbiased, fast convergence, etc.
	\end{itemize}
\end{frame}

\begin{frame}{Background}
	\begin{itemize}
		\item Lastly if the model is correctly specified, and all the identification assumptions are met, the parameters can be estimated.
		\item The identification method gives us the estimator.
		\item The estimator makes further assumptions about the data which again cannot always be verified.
	\end{itemize}
\end{frame}

\begin{frame}{Background: Examples}
	\begin{columns}
		\begin{column}{0.33 \textwidth}
			\center
			\begin{figure}
				$ A \rightarrow Y; A \leftarrow C \rightarrow Y $
				\caption{Backdoor criterion: No unobserved confounding.}
			\end{figure}
		\end{column}
		\begin{column}{0.33 \textwidth}
			\center
			\begin{figure}
				$ A \rightarrow M \rightarrow Y; A \leftarrow U \rightarrow Y  $
				\caption{Front-door: All effect mediated through $ A \rightarrow M $ edge.}
			\end{figure}
		\end{column}
		\begin{column}{0.33 \textwidth}
			\center
			\begin{figure}
				$ Z \rightarrow A; A \rightarrow Y; U \leftarrow A \rightarrow Y $
				\caption{Instrumental Variables; No correlation between $ Z $ and $ Y $ except going through $ A $.}
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Problem Statement}
	\begin{itemize}
		\item The paper limits to checking whether a causal effect is present or not.
		\item It is challenging to come up with a single correct specification of the model.
		\item Instead, use a bunch of different model. And the paper proposes a robustness test on this set of models.
		\item The test check if the causal assumption is true if atleast one of the specified model is correct.
		\item They use something called Evidence Factors to combine the results from testing on the models.
		\item Limited to semi-parameteric estimation methods. For convergence properties of the test??
	\end{itemize}
\end{frame}

\begin{frame}{Example}
	% TODO: Talk about the example they show in the paper.
	\begin{itemize}
		\item Interested in testing whether there is an effect of smoking on glucose levels.
		\item $ D = \{ C, Z, A, M, Y \} $. $ C $ is baseline covariates containing age, sex, BMI, past history of heart disease, and past glucose level.
		\item $ A $ is binary indicating current smoking status. Treatment of interest.
		\item $ Y $ is glucose level. Continuous outcome of interest.
		\item $ M $ is hypertension which is our candidate mediator.
		\item $ Z $ is past hypertension which can be our IV.
		\item Aim is to estimate the average causal effect (ACE) of smoking on glucose
	\end{itemize}
			$$ \beta = \mathbb{E}[Y(A=1)] - \mathbb{E}[Y(A=0)] $$
\end{frame}

\begin{frame}{Example}
	% TODO: Show Fig 1 here.
	\begin{itemize}
		\item Plausible models for the data.
		\item Backdoor model. Adjusting on $ C $ would give us the estimate for $ A \rightarrow Y $.
		\item But no unobserved confounding can be present $ U $, otherwise the effect is not identified.
		\item But possible that we missed to collect data on some of our covariates. For example, health consciousness is an unmeasured covariate. %TODO: Add what could be covariate.
	\end{itemize}
	$$ \Psi_{1, P} = \mathbb{E}[\mu(1, C) - \mu(0, C)] $$
	$$ \mu(a, c) = \mathbb{E}(Y | A=a, C=c) $$
\end{frame}

\begin{frame}{Example}
	\begin{itemize}
		\item Front-door model. $ M $ is the mediator here.
		\item Model allows for unobserved confounding between the treatment and outcome.
		\item But there can't be an effect between the unobserved variable and the mediator or direct effect between the treatment and outcome.
	\end{itemize}
	$$ \Psi_{2, P} = \mathbb{E}[\mathbb{E}[\gamma(M, C) | A = 1, C] - \mathbb{E}[\gamma(M, C) | A =0, C]] $$
	$$ \gamma(m, c) = \mathbb{E}[\mu(m, A, c) | C=c]; \mu(m, a, c) = \mathbb{E}(Y | M=m, A=a, C=c) $$
\end{frame}

\begin{frame}{Example}
	\begin{itemize}
		\item Instrumental Variable model. $ Z $ is the IV.
		\item $ Z $ should not be correlated with $ Y $ unless all information goes through $ A $.
	\end{itemize}
	$$ \Psi_{3, P} = \frac{\mathbb{E}(Y | Z = 1) - \mathbb{E}(Y | Z = 0)}{\mathbb{E}(A | Z = 1) - \mathbb{E}(A | Z=0)} $$
\end{frame}

\begin{frame}{Example}
	\begin{itemize}
		\item If a semi-parameteric estimator of the corresponding parameter exist, it can be used to construct a statistically robust hypothesis test of the causal null hypothesis $ \beta = 0 $.
		\item 
	\end{itemize}
\end{frame}

\begin{frame}{Evidence Factors}
\end{frame}

\begin{frame}{Proposed Solution Overview}
	$$ H_{0}: \beta = 0 $$
	IID data $ O_1, \cdots, O_n $ from unknown distribution $ P $.
	Considering $ K > 1 $ causal models $ M_1, \cdots, M_k $.
	$ \Psi_{k, P} $ is the identifying functional for $ \beta $ under $ M_k $.
\end{frame}

\begin{frame}{Proposed Solution}
\end{frame}

\begin{frame}{Applied to Practical Example}
\end{frame}

\begin{frame}{Real Data Example}
\end{frame}

\begin{frame}{Conclusion}
\end{frame}

\end{document}
