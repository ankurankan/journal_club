\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usecolortheme{beaver}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{titlecaps}
\usepackage{fancyvrb}

\def\ci{\perp\!\!\!\!\!\perp}

\newtheorem{proposition}{Proposition}
\Addlcwords{for a is but and with of in as the etc on to if}

\setbeamertemplate{section in toc}{\inserttocsectionnumber.~\inserttocsection}
\usetheme{Boadilla}
\makeatletter
\setbeamertemplate{footline}{%
    \leavevmode%
    \hbox{%
        \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
            \usebeamerfont{author in head/foot}\insertshortauthor\expandafter\beamer@ifempty\expandafter{\beamer@shortinstitute}{}{~~(\insertshortinstitute)}
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
            \usebeamerfont{title in head/foot}\insertshorttitle
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=.15\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
            \usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}
            \insertframenumber{} / \inserttotalframenumber\hspace*{2ex} 
        \end{beamercolorbox}}%
        \vskip0pt%
    }
\makeatother

\begin{document}

\title[]{Canonical Correlation Based Mixed Data Conditional Independence Testing: Emprirical Analysis}
\author{}
\date{}

\maketitle

\begin{frame}{Mixed Data CI Tests}
	\begin{enumerate}
		\item Mutual Information based test (MI-CG): Used as baseline; implemented in R package `bnlearn'
		\item Likelihood Ratio Test (MXM)
		\item Hotelling's $T^2$ test on mixed data residualization.
	\end{enumerate}
\end{frame}

\begin{frame}{Likelihood Ratio Test (MXM)}
\end{frame}

\begin{frame}{Hotelling's $ T^2 $ test}
Given two mixed data residual matrices, $ R_\mathbf{x} $ and $ R_\mathbf{y} $

$$ Q(\mathbf{x}, \mathbf{y}) = \frac{1}{n} \left( d \times \hat{\Sigma}_d \times d^T \right) $$


$$
d = (R_{\mathbb{I}(\mathbf{x}=1)} \cdot R_{(\mathbf{y}=1)}, \, \ldots \ ,
R_{\mathbb{I}(\mathbf{x}=C_x)} \cdot R_{(\mathbf{y}=C_y)} )
$$

$$ \hat{\Sigma}_d = cov(d) $$

Under null, $ Q $ is asymptotically $ \chi^2 (\mid R_\mathbf{x} \mid \times \mid R_\mathbf{y} \mid) $ distributed.

\end{frame}

\begin{frame}{Pillai's Trace}

$$ \textit{V}(R_\mathbf{x}, R_\mathbf{y}) = \sum_{\rho \in \bm{\rho}(R_\mathbf{x}, R_\mathbf{y})} \rho^2 $$

No exact asymptotic distribution, F-approximation is used.

\end{frame}

\begin{frame}{Simulating Mixed Data}
	Given a DAG, $ D $ we simulate the data as.
\end{frame}

\begin{frame}{Calibration: Data Generation}
	We use the DAG:
\end{frame}

\begin{frame}{Calibration}
	Insert figure here.
\end{frame}

\begin{frame}{Accuracy: Data Generation}
	We use the DAG:
\end{frame}

\begin{frame}{Accuracy}
	Insert figure here.
\end{frame}

\begin{frame}{Structure Learning: Data Generation}
	DAG generation mechanism.
\end{frame}

\begin{frame}{Structure Learning}
\end{frame}

\begin{frame}{Conclusion}
	\begin{itemize}
		\item Pillai's Trace is better calibrated especially in high-dimensional scenarios.
	\end{itemize}
\end{frame}

\end{document}
