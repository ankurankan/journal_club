\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usecolortheme{beaver}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{titlecaps}
\usepackage{fancyvrb}

\def\ci{\perp\!\!\!\!\!\perp}

\newtheorem{proposition}{Proposition}
\Addlcwords{for a is but and with of in as the etc on to if}

\setbeamertemplate{section in toc}{\inserttocsectionnumber.~\inserttocsection}
\usetheme{Boadilla}
\makeatletter
\setbeamertemplate{footline}{%
    \leavevmode%
    \hbox{%
        \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
            \usebeamerfont{author in head/foot}\insertshortauthor\expandafter\beamer@ifempty\expandafter{\beamer@shortinstitute}{}{~~(\insertshortinstitute)}
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=.55\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
            \usebeamerfont{title in head/foot}\insertshorttitle
        \end{beamercolorbox}%
        \begin{beamercolorbox}[wd=.15\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
            \usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}
            \insertframenumber{} / \inserttotalframenumber\hspace*{2ex} 
        \end{beamercolorbox}}%
        \vskip0pt%
    }
\makeatother

\begin{document}

\title[]{Expert-in-the-Loop Structure Learning}
\author{Ankur Ankan}
\date{}

\maketitle

\begin{frame}{Background}
	\todo[inline]{Add an example of a DAG here}
	
	\begin{itemize}
		\item Nodes represent random variables.
		\item Directed edges represent causal relationships between them.
	\end{itemize}
\end{frame}

\begin{frame}{Structure Learning: Learning DAGs from data}
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\node[draw, rectangle] (x) at ( 0, 0 ) { Observational Data };
			\node[draw, rectangle] (y) at ( 6, 0 ) { CPDAG };
			\node[draw, rectangle] (z) at ( 10, 0) { DAG };
		
			\draw[->](x) -- (y) node[midway, below, yshift=0.1cm]{ Structure Learning };
			\draw[->](y) -- (z) node[midway, below, yshift=0.1cm]{ Edge orientation };
		\end{tikzpicture}
	\end{figure}
	\todo[inline]{Improve the figure. Show an example right below the steps }

	\begin{itemize}
		\item With structure learning, we want to recover the true data generating DAG.
		\item Many algorithms have been proposed such as constraint-based PC, FCI, etc. score-based Hill-Climb, GES.
		\item Algorithms can only recover CPDAGs.
		\item Further analysis can be done either on CPDAGs or can need to orient the edges based on expert knowledge.
	\end{itemize}
\end{frame}

\begin{frame}{Structure Learning in Practice}
	\begin{itemize}
		\item Adaption of these structure learning algorithms have been very limited.
		\item Researchers still prefer to draw their models by hand based on their domain knowledge.
		\item Potential reasons could be:
			\begin{itemize}
				\item Algorithms can make obvious mistakes sometimes, making it harder to trust.
				\item A lot of different algorithms with different assumptions making it hard to make a choice.
			\end{itemize}
		\item Some of them test their model after drawing.
	\end{itemize}
\end{frame}

\begin{frame}{Model Testing}
	\todo[inline]{Add an example of model testing here}

	\begin{itemize}
		\item Test for missing edges in the model.
		\item If the test fails, it implies that the correlation between the variables is not explained by the model.
		\item The model is then modified to make it more agreeable with the data.
	\end{itemize}
\end{frame}

\begin{frame}{Human-in-the-loop Structure Learning}
	\begin{itemize}
		\item As most models are built by hand, a tool that can help with building these models with the help of testing.
	\end{itemize}
\end{frame}

\begin{frame}{Show an example of how this works}
\end{frame}

\begin{frame}{An effect size for mixed data}
\end{frame}


\begin{frame}{Empirical Analysis}
	\begin{itemize}
		\item Random DAGs on $ 10 $ nodes are generated.
		\item Data is simulated from these DAGs using linear models with random parameters.
		\item We use the simulated data to learn back the original model.
		\item We then compare the Structural Hamming Distance and Structural Intervention distance between the true and the learned graph.
		\item Because the structure learning algorithms can only learn the CPDAG, we show the best case and worst case DAGs.
	\end{itemize}
\end{frame}

\begin{frame}{Empirical Analysis}
	Need to simulate how an expert would use this to build DAGs.
	\begin{itemize}
		\item Take a greedy approach and choose the edge with the highest effect.
		\item After each edge addition the effects are updated.
		\item A pruning step is done to check if adding an edge removes some of the effects.
		\item An oracle is used to determine the direction of the edge. With some given confidence, the oracle either gives
			a correct answer or randomly.
	\end{itemize}
\end{frame}

\begin{frame}{Empirical Analysis: Structural Hamming Distance}
	\begin{figure}
		\centering
		\includegraphics[scale=0.9]{../../2024-human-sl/code/plots/shd_ribbon.pdf}
		\caption{SHD vs edge probability}
	\end{figure}
\end{frame}

\begin{frame}{Empirical Analysis: Structural Hamming Distance}
	\begin{figure}
		\centering
		\includegraphics[scale=0.9]{../../2024-human-sl/code/plots/sid_ribbon.pdf}
		\caption{SID vs edge probability}
	\end{figure}
\end{frame}

\begin{frame}{Conclusion}
	\begin{itemize}
		\item We propose a tool to interactively draw DAGs combining it with testing.
		\item We propose an effect size measure for mixed data.
		\item For oracles with decent accuracy the method works well.
		\item Oracles can be replaced with LLMs.
	\end{itemize}
\end{frame}

\end{document}
