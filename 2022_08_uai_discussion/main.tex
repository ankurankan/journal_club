\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usecolortheme{beaver}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{mathtools}
\usepackage{bm}
\usepackage[style=verbose, backend=biber]{biblatex}

\begin{document}

\begin{frame}
	\frametitle{Summary}
	\begin{itemize}
		\item For causal estimation, regularization methods for dealing
			with multicolinearity and high-dimensional dataset can
			lead to biased estimates.
		\item A new regularization term is introduced that does a
			``partial'' regularization on only some of the
			covariates.
		\item The concept of collapsibility is extended to regularized
			regression analysis.
	\end{itemize}

\end{frame}

\begin{frame}
	\frametitle{Discussion Points}
	\begin{itemize}
		\item Best strategies for selecting the confounding set, $
			\bm{W} $, and the set of possible confounders, $ \bm{Z}
			$.
		\item Choosing the optimal hyperparameters. Grid search for best 
			predictive performance or any other better strategies?
		\item Extending it to other statistical models like Generalized
			Linear Models, Generalized Estimating Equations, etc.
	\end{itemize}
\end{frame}

\end{document}
